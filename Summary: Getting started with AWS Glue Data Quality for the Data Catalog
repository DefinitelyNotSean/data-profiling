The AWS Glue Data Quality service enables you to measure and monitor the quality of your data for sound business decision-making. It is built on the open-source DeeQu framework and offers a managed, serverless experience. Key features include serverless operation, quick start capabilities, machine learning-driven data quality issue detection, customizable data quality rules, data quality scoring for informed decisions, pinpointing problematic data, pay-as-you-go pricing, and no lock-in due to its open-source foundation. It also supports data quality checks in both AWS Glue Data Catalog and AWS Glue ETL pipelines​​.

AWS Glue Data Quality can be accessed via two main entry points: AWS Glue Data Catalog and AWS Glue ETL jobs. The Data Catalog option is designed for non-coders like data stewards and business analysts, allowing them to easily set up data quality rules. In contrast, the AWS Glue ETL jobs option focuses on proactive data quality tasks to identify and filter out bad data before loading it into a data lake​​​​.

The service supports various features, such as data quality rule recommendations, authoring and running DQDL rules, auto-scaling, and integration with Amazon Eventbridge and AWS Cloudwatch, among others. However, it's important to note that data quality rules in AWS Glue cannot evaluate nested or list-type data sources​​​​.

Key terms related to AWS Glue Data Quality include Data Quality Definition Language (DQDL), data quality score, rule, analyzer, ruleset, and observation, each having specific functions and significance in the context of data quality management​​.
